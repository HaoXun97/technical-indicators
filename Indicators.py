import yfinance as yf
import pandas as pd
from pandas import DataFrame, Series, Index
import numpy as np
import talib
from talib._ta_lib import MA_Type
import json
import logging
from datetime import datetime
from typing import Dict, Optional, List, Any, Union, Literal
from pathlib import Path
from dataclasses import dataclass
from enum import Enum
import sys

# è¨­å®šè­¦å‘Šå’Œæ—¥èªŒ
import warnings

warnings.filterwarnings("ignore")
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


class TimeInterval(Enum):
    """æ™‚é–“é–“éš”æšèˆ‰"""

    MINUTE_1 = "1m"
    MINUTE_5 = "5m"
    MINUTE_15 = "15m"
    MINUTE_30 = "30m"
    HOUR_1 = "1h"
    DAY_1 = "1d"
    WEEK_1 = "1wk"
    MONTH_1 = "1mo"


class Period(Enum):
    """æ™‚é–“é€±æœŸæšèˆ‰"""

    DAY_1 = "1d"
    DAY_5 = "5d"
    MONTH_1 = "1mo"
    MONTH_3 = "3mo"
    MONTH_6 = "6mo"
    YEAR_1 = "1y"
    YEAR_2 = "2y"
    YEAR_5 = "5y"
    YEAR_10 = "10y"
    MAX = "max"


@dataclass
class StockPrice:
    """è‚¡åƒ¹æ•¸æ“šçµæ§‹"""

    open: float
    high: float
    low: float
    close: float
    volume: int


@dataclass
class TechnicalIndicators:
    """æŠ€è¡“æŒ‡æ¨™æ•¸æ“šçµæ§‹"""

    rsi_14: Optional[float] = None
    rsi_5: Optional[float] = None
    macd: Optional[float] = None
    macd_signal: Optional[float] = None
    macd_histogram: Optional[float] = None
    rsv: Optional[float] = None
    k_percent: Optional[float] = None
    d_percent: Optional[float] = None
    j_percent: Optional[float] = None
    bb_upper: Optional[float] = None
    bb_middle: Optional[float] = None
    bb_lower: Optional[float] = None
    ma_5: Optional[float] = None
    ma_10: Optional[float] = None
    ma_20: Optional[float] = None
    ma_60: Optional[float] = None
    ema_12: Optional[float] = None
    ema_26: Optional[float] = None
    atr: Optional[float] = None
    cci: Optional[float] = None
    willr: Optional[float] = None


class DataProvider:
    """æ•¸æ“šæä¾›è€…é¡åˆ¥"""

    def __init__(self) -> None:
        self.logger = logging.getLogger(__name__)
        self._cache = {}

    def get_stock_data(
        self,
        symbol: str,
        period: Union[Period, str],
        interval: Union[TimeInterval, str],
        use_cache: bool = True,
    ) -> Optional[DataFrame]:
        """ç²å–è‚¡ç¥¨æ•¸æ“š"""
        try:
            formatted_symbol: str = self._format_symbol(symbol)

            # æå–æšèˆ‰å€¼
            period_str: str | Any = (
                period.value if isinstance(period, Period) else period
            )
            interval_str: str | Any = (
                interval.value if isinstance(
                    interval, TimeInterval) else interval
            )

            cache_key: str = f"{formatted_symbol}_{period_str}_{interval_str}"

            if use_cache and cache_key in self._cache:
                self.logger.info(f"å¾å¿«å–ç²å– {formatted_symbol} æ•¸æ“š")
                return self._cache[cache_key]

            # èª¿æ•´æœŸé–“ä»¥é¿å…APIé™åˆ¶
            adjusted_period: str = self._adjust_period_for_interval(
                period_str, interval_str
            )

            ticker: yf.Ticker = yf.Ticker(formatted_symbol)

            # æ·»åŠ é¡å¤–çš„éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶
            import time
            max_retries = 3
            data: DataFrame = DataFrame()  # åˆå§‹åŒ– data è®Šæ•¸
            for attempt in range(max_retries):
                try:
                    data = ticker.history(
                        period=adjusted_period,
                        interval=interval_str,
                        timeout=10  # æ·»åŠ è¶…æ™‚è¨­å®š
                    )
                    break
                except Exception as retry_error:
                    if attempt < max_retries - 1:
                        self.logger.warning(
                            f"å˜—è©¦ {attempt + 1} ç²å– {formatted_symbol} "
                            f"å¤±æ•—ï¼Œé‡è©¦ä¸­...")
                        time.sleep(1)  # ç­‰å¾…1ç§’å¾Œé‡è©¦
                        continue
                    else:
                        raise retry_error

            if data.empty:
                self.logger.warning(f"ç„¡æ³•ç²å– {formatted_symbol} çš„æ•¸æ“š")
                return None

            self.logger.info(f"æˆåŠŸç²å– {formatted_symbol} æ•¸æ“š: {len(data)} ç­†")

            if use_cache:
                self._cache[cache_key] = data

            return data

        except Exception as e:
            self.logger.error(f"ç²å– {symbol} æ•¸æ“šéŒ¯èª¤: {e}")
            return None

    def _format_symbol(self, symbol: str) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨ä»£è™Ÿ"""
        # å°æ–¼å°è‚¡ï¼Œæ·»åŠ  .TW å¾Œç¶´
        if symbol.isdigit() and len(symbol) == 4:
            return f"{symbol}.TW"

        # å¦‚æœå·²ç¶“æœ‰å¾Œç¶´ï¼Œç›´æ¥è¿”å›
        if symbol.endswith((".TW", ".TWO")):
            return symbol

        # ç¾è‚¡ä»£è™Ÿç‰¹å¾µï¼š
        # 1. åŒ…å«è‹±æ–‡å­—æ¯
        # 2. é•·åº¦é€šå¸¸åœ¨1-5å€‹å­—ç¬¦
        # 3. å¯èƒ½åŒ…å«æ•¸å­—ä½†ä¸æ˜¯ç´”æ•¸å­—
        if (any(c.isalpha() for c in symbol) and
            len(symbol) <= 5 and
                not symbol.isdigit()):
            return symbol

        # é»˜èªæƒ…æ³ï¼Œå‡è¨­æ˜¯å°è‚¡
        return f"{symbol}.TW"

    def _adjust_period_for_interval(self, period: str, interval: str) -> str:
        """æ ¹æ“šé–“éš”èª¿æ•´æœŸé–“"""
        if interval in ["1h", "2h", "4h", "6h", "12h"]:
            if period in ["max", "5y", "10y"]:
                return "730d"
        elif interval in ["1m", "2m", "5m", "15m", "30m", "90m"]:
            if period in ["max", "5y", "10y", "2y", "1y"]:
                return "60d"

        return period


class IndicatorCalculator:
    """æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å™¨"""

    def __init__(self) -> None:
        self.logger = logging.getLogger(__name__)

    def calculate_all_indicators(self, data: DataFrame) -> Dict[str, Series]:
        """è¨ˆç®—æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™"""
        if not isinstance(data, DataFrame) or data.empty:
            raise ValueError("æ•¸æ“šå¿…é ˆæ˜¯éç©ºçš„ DataFrame")

        if len(data) < 60:
            self.logger.warning("æ•¸æ“šé•·åº¦ä¸è¶³ï¼ŒæŸäº›æŒ‡æ¨™å¯èƒ½ç„¡æ³•è¨ˆç®—")

        # è½‰æ›ç‚º numpy arrays
        high: np.ndarray = data["High"].values.astype("float64")
        low: np.ndarray = data["Low"].values.astype("float64")
        close: np.ndarray = data["Close"].values.astype("float64")
        volume: np.ndarray = data["Volume"].values.astype("float64")

        indicators: dict[str, Series] = {}

        try:
            # RSI æŒ‡æ¨™
            indicators.update(self._calculate_rsi(close, data.index))

            # MACD æŒ‡æ¨™
            indicators.update(self._calculate_macd(close, data.index))

            # KD æŒ‡æ¨™
            indicators.update(self._calculate_stochastic(
                high, low, close, data.index))

            # ç§»å‹•å¹³å‡ç·š
            indicators.update(
                self._calculate_moving_averages(close, data.index))

            # å¸ƒæ—é€šé“
            indicators.update(
                self._calculate_bollinger_bands(close, data.index))

            # å…¶ä»–æŒ‡æ¨™
            indicators.update(
                self._calculate_other_indicators(
                    high, low, close, volume, data.index)
            )

        except Exception as e:
            self.logger.error(f"è¨ˆç®—æŒ‡æ¨™éŒ¯èª¤: {e}")
            return {}

        return indicators

    def _calculate_rsi(
        self, close: np.ndarray, index: Index
    ) -> Dict[str, Series]:
        """è¨ˆç®— RSI æŒ‡æ¨™"""
        return {
            "RSI(5)": Series(talib.RSI(close, timeperiod=5), index=index),
            "RSI(7)": Series(talib.RSI(close, timeperiod=7), index=index),
            "RSI(10)": Series(talib.RSI(close, timeperiod=10), index=index),
            "RSI(14)": Series(talib.RSI(close, timeperiod=14), index=index),
            "RSI(21)": Series(talib.RSI(close, timeperiod=21), index=index),
        }

    def _calculate_macd(
        self, close: np.ndarray, index: Index
    ) -> Dict[str, Series]:
        """è¨ˆç®— MACD æŒ‡æ¨™"""
        macd_line, signal_line, macd_histogram = talib.MACD(
            close, fastperiod=12, slowperiod=26, signalperiod=9
        )
        return {
            "DIF": Series(macd_line, index=index),
            "MACD": Series(signal_line, index=index),
            "MACD_Histogram": Series(macd_histogram, index=index),
        }

    def _calculate_stochastic(
        self,
        high: np.ndarray,
        low: np.ndarray,
        close: np.ndarray,
        index: Index
    ) -> Dict[str, Series]:
        """è¨ˆç®— KDJ æŒ‡æ¨™"""

        # è¨ˆç®— RSV (Raw Stochastic Value)
        # RSV = (æ”¶ç›¤åƒ¹ - æœ€è¿‘ n æ—¥æœ€ä½åƒ¹) / (æœ€è¿‘ n æ—¥æœ€é«˜åƒ¹ - æœ€è¿‘ n æ—¥æœ€ä½åƒ¹) * 100
        n = 9  # KD æŒ‡æ¨™çš„é€±æœŸåƒæ•¸

        rsv: np.ndarray = np.full(len(close), np.nan)
        k_values: np.ndarray = np.full(len(close), np.nan)
        d_values: np.ndarray = np.full(len(close), np.nan)

        for i in range(n - 1, len(close)):
            # è¨ˆç®—æœ€è¿‘ n æ—¥çš„æœ€é«˜åƒ¹å’Œæœ€ä½åƒ¹
            period_high: float = np.max(high[i - n + 1: i + 1])
            period_low: float = np.min(low[i - n + 1: i + 1])

            # è¨ˆç®— RSV
            if period_high != period_low:
                rsv_value = ((close[i] - period_low) /
                             (period_high - period_low)) * 100
                # ç¢ºä¿ RSV å€¼åœ¨ 0-100 ç¯„åœå…§
                rsv[i] = max(0, min(100, rsv_value))
            else:
                rsv[i] = 50  # é¿å…é™¤é›¶éŒ¯èª¤

        # åˆå§‹åŒ– K å’Œ D å€¼
        # ç¬¬ä¸€å€‹ K å€¼é€šå¸¸è¨­ç‚º 50ï¼Œæˆ–ä½¿ç”¨ RSV å€¼
        first_valid_idx: int = n - 1
        k_values[first_valid_idx] = (
            rsv[first_valid_idx] if not np.isnan(rsv[first_valid_idx]) else 50
        )
        d_values[first_valid_idx] = k_values[first_valid_idx]

        # è¨ˆç®— K å’Œ D å€¼
        for i in range(first_valid_idx + 1, len(close)):
            if not np.isnan(rsv[i]):
                # K = 2/3 Ã— K å‰ä¸€æ—¥ + 1/3 Ã— RSV
                k_values[i] = (2 / 3) * k_values[i - 1] + (1 / 3) * rsv[i]
                # D = 2/3 Ã— D å‰ä¸€æ—¥ + 1/3 Ã— K
                d_values[i] = (2 / 3) * d_values[i - 1] + (1 / 3) * k_values[i]

        # è¨ˆç®— J æŒ‡æ¨™ï¼šJ = 3 * K - 2 * D
        j_values = 3 * k_values - 2 * d_values

        return {
            "RSV": Series(rsv, index=index),
            "K": Series(k_values, index=index),
            "D": Series(d_values, index=index),
            "J": Series(j_values, index=index),
        }

    def _calculate_moving_averages(
        self, close: np.ndarray, index: Index
    ) -> Dict[str, Series]:
        """è¨ˆç®—ç§»å‹•å¹³å‡ç·š"""
        indicators: dict[str, Series] = {}

        # ç°¡å–®ç§»å‹•å¹³å‡ç·š
        for period in [5, 10, 20, 60]:
            indicators[f"MA{period}"] = Series(
                talib.SMA(close, timeperiod=period), index=index
            )

        # æŒ‡æ•¸ç§»å‹•å¹³å‡ç·š
        indicators["EMA12"] = Series(
            talib.EMA(close, timeperiod=12), index=index)
        indicators["EMA26"] = Series(
            talib.EMA(close, timeperiod=26), index=index)

        return indicators

    def _calculate_bollinger_bands(
        self, close: np.ndarray, index: Index
    ) -> Dict[str, Series]:
        """è¨ˆç®—å¸ƒæ—é€šé“"""
        bb_upper, bb_middle, bb_lower = talib.BBANDS(
            close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=MA_Type.SMA
        )
        return {
            "BB_Upper": Series(bb_upper, index=index),
            "BB_Middle": Series(bb_middle, index=index),
            "BB_Lower": Series(bb_lower, index=index),
        }

    def _calculate_other_indicators(
        self,
        high: np.ndarray,
        low: np.ndarray,
        close: np.ndarray,
        volume: np.ndarray,
        index: Index,
    ) -> Dict[str, Series]:
        """è¨ˆç®—å…¶ä»–æŠ€è¡“æŒ‡æ¨™"""
        return {
            "ATR": Series(
                talib.ATR(high, low, close, timeperiod=14), index=index
            ),
            "CCI": Series(
                talib.CCI(high, low, close, timeperiod=14), index=index
            ),
            "WILLR": Series(
                talib.WILLR(high, low, close, timeperiod=20), index=index
            ),
            "MOM": Series(
                talib.MOM(close, timeperiod=10), index=index
            ),
        }


class ResultExporter:
    """çµæœåŒ¯å‡ºå™¨"""

    def __init__(self, output_dir: str = "output") -> None:
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.logger = logging.getLogger(__name__)

    def save_to_json(
        self, results: Dict[str, Any], filename: Optional[str] = None
    ) -> str:
        """ä¿å­˜çµæœç‚º JSON"""
        if filename is None:
            filename = "analysis.json"

        filepath: Path = self.output_dir / filename

        try:
            # æ¸…ç†çµæœï¼Œç§»é™¤ç„¡æ³•åºåˆ—åŒ–çš„ç‰©ä»¶
            clean_results: dict[str,
                                Any] = self._clean_results_for_json(results)

            existing_data: Dict[str, Any] = {}
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”éç©º
            if filepath.exists() and filepath.stat().st_size > 0:
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        existing_data = json.load(f)
                    if not isinstance(existing_data, dict):  # ç¢ºä¿è®€å–çš„æ˜¯å­—å…¸
                        self.logger.warning(
                            f"ç¾æœ‰çš„ JSON æª”æ¡ˆ {filepath} æ ¼å¼ä¸æ­£ç¢ºï¼Œå°‡æœƒè¦†å¯«ã€‚")
                        existing_data = {}
                except json.JSONDecodeError:
                    self.logger.warning(f"ç„¡æ³•è§£æç¾æœ‰çš„ JSON æª”æ¡ˆ {filepath}ã€‚å°‡æœƒè¦†å¯«ã€‚")
                    existing_data = {}  # å¦‚æœè§£æå¤±æ•—ï¼Œå‰‡è¦–ç‚ºç©ºå­—å…¸ï¼Œé¿å…éŒ¯èª¤
                except Exception as e:
                    self.logger.error(f"è®€å–ç¾æœ‰ JSON æª”æ¡ˆ {filepath} éŒ¯èª¤: {e}ã€‚å°‡æœƒè¦†å¯«ã€‚")
                    existing_data = {}  # å…¶ä»–éŒ¯èª¤ä¹Ÿè¦–ç‚ºç©ºå­—å…¸

            # åˆä½µæ•¸æ“šï¼šæ–°çš„çµæœæœƒè¦†å¯«æˆ–æ·»åŠ æ¢ç›®
            # ç¢ºä¿ existing_data æ˜¯ä¸€å€‹å­—å…¸ä»¥ä½¿ç”¨ update æ–¹æ³•
            if not isinstance(existing_data, dict):
                existing_data = {}
            existing_data.update(clean_results)

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(existing_data, f, ensure_ascii=False,
                          indent=2, default=str)

            return str(filepath)

        except Exception as e:
            self.logger.error(f"ä¿å­˜ JSON éŒ¯èª¤: {e}")
            return ""

    def save_to_csv(
        self, symbol: str, data: DataFrame, indicators: Dict[str, Series]
    ) -> str:
        """ä¿å­˜æ­·å²æ•¸æ“šç‚º CSVï¼Œå¦‚æœæª”æ¡ˆå·²å­˜åœ¨å‰‡æ›´æ–°å…§å®¹ã€‚"""
        try:
            # 1. æº–å‚™ new_combined_dataï¼Œä¸¦æ ¼å¼åŒ–å…¶ 'Date' ç´¢å¼•
            new_combined_data: DataFrame = data.copy()
            for name, series in indicators.items():
                new_combined_data[name] = series

            if isinstance(new_combined_data.index, pd.DatetimeIndex):
                if new_combined_data.index.tz is not None:
                    import pytz  # ç¢ºä¿ pytz å·²åŒ¯å…¥
                    taiwan_tz = pytz.timezone('Asia/Taipei')
                    new_combined_data.index = (
                        new_combined_data.index.tz_convert(taiwan_tz)
                        .tz_localize(None)
                    )
                new_combined_data.index = pd.Index([
                    dt.strftime('%Y-%m-%d %H:%M:%S')
                    for dt in new_combined_data.index
                ], name='Date')
            elif new_combined_data.index.name != 'Date':
                # å¦‚æœç´¢å¼•ä¸æ˜¯ DatetimeIndexï¼Œä½†åç¨±ä¸æ˜¯ 'Date'ï¼Œå‰‡è¨­å®šåç¨±
                # å‡è¨­æ­¤æ™‚ç´¢å¼•å·²ç¶“æ˜¯æ­£ç¢ºçš„æ—¥æœŸå­—ä¸²æ ¼å¼
                self.logger.debug(
                    f"CSV Index for {symbol} is not DatetimeIndex and not "
                    f"named 'Date'. Current name: "
                    f"{new_combined_data.index.name}. Setting to 'Date'."
                )
                new_combined_data.index.name = 'Date'

            filename: str = f"{symbol}.csv"
            filepath: Path = self.output_dir / filename
            final_df: DataFrame

            # 2. å¦‚æœæª”æ¡ˆå­˜åœ¨ï¼Œè®€å–ä¸¦åˆä½µ
            if filepath.exists() and filepath.stat().st_size > 0:
                try:
                    existing_df = pd.read_csv(
                        filepath, index_col='Date', encoding='utf-8-sig'
                    )
                    # ç¢ºä¿ existing_df çš„ç´¢å¼•æ˜¯å­—ä¸²é¡å‹ä¸”åç‚º 'Date'
                    if isinstance(existing_df.index, pd.DatetimeIndex):
                        existing_df.index = existing_df.index.strftime(
                            '%Y-%m-%d %H:%M:%S'
                        )
                    else:  # å¦‚æœå·²æ˜¯ object/stringï¼Œç¢ºä¿æ˜¯ str
                        existing_df.index = existing_df.index.astype(str)
                    existing_df.index.name = 'Date'

                    # åˆä½µæ•¸æ“šï¼šnew_combined_data çš„æ•¸æ“šå„ªå…ˆ
                    # concat å¾Œï¼Œå°æ–¼é‡è¤‡çš„ç´¢å¼•ï¼ˆæ—¥æœŸï¼‰ï¼Œä¿ç•™æœ€å¾Œä¸€å€‹ï¼ˆå³ä¾†è‡ª new_combined_dataï¼‰
                    merged_df = pd.concat([existing_df, new_combined_data])
                    final_df = merged_df[
                        ~merged_df.index.duplicated(keep='last')
                    ]
                    final_df = final_df.sort_index()
                    self.logger.info(f"å·²æ›´æ–° CSV æª”æ¡ˆ: {filepath}")

                except pd.errors.EmptyDataError:
                    self.logger.warning(
                        f"ç¾æœ‰çš„ CSV æª”æ¡ˆ {filepath} ç‚ºç©ºã€‚å°‡å‰µå»ºæ–°æª”æ¡ˆã€‚"
                    )
                    final_df = new_combined_data.sort_index()
                except Exception as e_read:
                    self.logger.warning(
                        f"è®€å–æˆ–åˆä½µç¾æœ‰ CSV æª”æ¡ˆ {filepath} éŒ¯èª¤: {e_read}ã€‚"
                        "å°‡è¦†å¯«ã€‚"
                    )
                    final_df = new_combined_data.sort_index()
            else:
                # æª”æ¡ˆä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œç›´æ¥ä½¿ç”¨æ–°æ•¸æ“š
                final_df = new_combined_data.sort_index()
                if filepath.exists():  # æª”æ¡ˆå­˜åœ¨ä½†æ˜¯ç©ºçš„
                    self.logger.info(
                        f"ç¾æœ‰çš„ CSV æª”æ¡ˆ {filepath} ç‚ºç©ºã€‚å°‡å¯«å…¥æ–°æ•¸æ“šã€‚"
                    )
                else:
                    self.logger.info(
                        f"CSV æª”æ¡ˆä¸å­˜åœ¨ã€‚å°‡å‰µå»ºæ–°æª”æ¡ˆ: {filepath}"
                    )

            # 3. ä¿å­˜æœ€çµ‚çš„ DataFrame (ä¿®æ­£ä¸Šä¸€ç‰ˆæœ¬ä¸­éŒ¯èª¤çš„ç·¨è™Ÿ)
            final_df.to_csv(filepath, encoding="utf-8-sig", index=True)
            return str(filepath)

        except Exception as e:
            self.logger.error(f"ä¿å­˜ CSV éŒ¯èª¤ ({symbol}): {e}")
            return ""

    def _clean_results_for_json(
        self, results: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ¸…ç†çµæœä»¥ä¾¿ JSON åºåˆ—åŒ–"""
        clean_results: Dict[str, Dict[str, Any]] = {}
        for symbol, data in results.items():
            if isinstance(data, dict):
                clean_data: Dict[str, Any] = {
                    k: v for k, v in data.items() if not k.startswith("_")
                }
                clean_results[symbol] = clean_data
            else:
                clean_results[symbol] = data
        return clean_results


class TechnicalAnalyzer:
    """æŠ€è¡“åˆ†æå™¨ä¸»é¡åˆ¥"""

    def __init__(self, output_dir: str = "output") -> None:
        self.data_provider = DataProvider()
        self.indicator_calculator = IndicatorCalculator()
        self.exporter = ResultExporter(output_dir)
        self.logger = logging.getLogger(__name__)

    def analyze_stock(
        self,
        symbol: str,
        period: Union[Period, str] = Period.YEAR_2,
        interval: Union[TimeInterval, str] = TimeInterval.DAY_1,
    ) -> Dict[str, Any]:
        """åˆ†æå–®ä¸€è‚¡ç¥¨"""
        try:
            # ç²å–æ•¸æ“š
            data: DataFrame | None = self.data_provider.get_stock_data(
                symbol, period, interval
            )
            if data is None:
                return {"error": f"ç„¡æ³•ç²å– {symbol} çš„æ•¸æ“š"}

            if len(data) < 60:
                return {"error": f"{symbol} æ•¸æ“šä¸è¶³ï¼ˆéœ€è¦è‡³å°‘60ç­†æ•¸æ“šï¼‰"}

            # è¨ˆç®—æŒ‡æ¨™
            indicators: dict[str, Series] = (
                self.indicator_calculator.calculate_all_indicators(data)
            )
            if not indicators:
                return {"error": f"ç„¡æ³•è¨ˆç®— {symbol} çš„æŠ€è¡“æŒ‡æ¨™"}

            # çµ„è£çµæœ
            latest: Series = data.iloc[-1]
            interval_str: str | Any = (
                interval.value if isinstance(
                    interval, TimeInterval) else interval
            )

            result: dict[str, Any] = {
                "symbol": symbol,
                "date": pd.to_datetime(data.index[-1]).strftime(
                    "%Y-%m-%d %H:%M:%S"
                ),
                "price": StockPrice(
                    open=float(latest["Open"]),
                    high=float(latest["High"]),
                    low=float(latest["Low"]),
                    close=float(latest["Close"]),
                    volume=int(latest["Volume"]),
                ).__dict__,
                "indicators": self._get_latest_indicator_values(indicators),
                "total_records": len(data),
                "interval": interval_str,
                "period": (
                    period.value if isinstance(period, Period) else period
                ),
                "time_range": (
                    f"{pd.to_datetime(data.index[0]).strftime('%Y-%m-%d')} - "
                    f"{pd.to_datetime(data.index[-1]).strftime('%Y-%m-%d')}"
                ),
                "analysis_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "_data": data,
                "_indicators": indicators,
            }

            return result

        except Exception as e:
            self.logger.error(f"åˆ†æ {symbol} éŒ¯èª¤: {e}")
            return {"error": f"åˆ†æ {symbol} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"}

    def analyze_multiple_stocks(
        self,
        symbols: List[str],
        period: Union[Period, str] = Period.YEAR_2,
        interval: Union[TimeInterval, str] = TimeInterval.DAY_1,
    ) -> Dict[str, Any]:
        """åˆ†æå¤šå€‹è‚¡ç¥¨"""
        results: dict[str, dict[str, Any]] = {}

        for symbol in symbols:
            self.logger.info(f"æ­£åœ¨åˆ†æ {symbol}...")
            results[symbol] = self.analyze_stock(symbol, period, interval)

        return results

    def save_analysis_results(
        self, results: Dict[str, Any], format_type: str = "json"
    ) -> List[str]:
        """ä¿å­˜åˆ†æçµæœ"""
        saved_files: list[str] = []

        if format_type.lower() == "json":
            json_file: str = self.exporter.save_to_json(results)
            if json_file:
                saved_files.append(json_file)

        # ä¿å­˜ CSV
        for symbol, result in results.items():
            if ("error" not in result and "_data" in result and
                    "_indicators" in result):
                csv_file: str = self.exporter.save_to_csv(
                    symbol, result["_data"], result["_indicators"]
                )
                if csv_file:
                    saved_files.append(csv_file)

        return saved_files

    def _get_latest_indicator_values(
        self, indicators: Dict[str, Series]
    ) -> Dict[str, Optional[float]]:
        """ç²å–æŒ‡æ¨™çš„æœ€æ–°å€¼"""
        latest_values: dict[str, float | None] = {}

        for name, series in indicators.items():
            if isinstance(series, Series) and not series.empty:
                latest_value: Any = series.iloc[-1]
                latest_values[name] = (
                    float(latest_value) if not pd.isna(latest_value) else None
                )

        return latest_values


class AnalysisReporter:
    """åˆ†æå ±å‘Šç”Ÿæˆå™¨"""

    @staticmethod
    def print_analysis_summary(results: Dict[str, Any]) -> None:
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n=== æŠ€è¡“åˆ†æçµæœæ‘˜è¦ ===")

        for symbol, data in results.items():
            if "error" in data:
                print(f"\nâŒ {symbol}: {data['error']}")
                continue

            print(f"\nğŸ“Š {symbol} ({data['date']}):")
            price: Any = data["price"]
            print(
                f"   åƒ¹æ ¼: é–‹ {price['open']:.2f} | "
                f"é«˜ {price['high']:.2f} | "
                f"ä½ {price['low']:.2f} | "
                f"æ”¶ {price['close']:.2f}"
            )
            print(f"   æˆäº¤é‡: {price['volume']:,}")

            indicators: Any = data["indicators"]

            # é¡¯ç¤ºé—œéµæŒ‡æ¨™
            if indicators.get("RSI(14)"):
                rsi: float = indicators["RSI(14)"]
                rsi_status: Literal["è¶…è²·", "è¶…è³£", "æ­£å¸¸"] = (
                    "è¶…è²·" if rsi > 70 else "è¶…è³£" if rsi < 30 else "æ­£å¸¸"
                )
                print(f"   RSI(14): {rsi:.2f} ({rsi_status})")
            else:
                print("   RSI(14): N/A")

            if indicators.get("DIF") and indicators.get("MACD"):
                macd_trend: Literal["å¤šé ­", "ç©ºé ­"] = (
                    "å¤šé ­" if indicators["DIF"] > indicators["MACD"] else "ç©ºé ­"
                )
                print(
                    f"   MACD: {indicators['MACD']:.4f} | "
                    f"DIF: {indicators['DIF']:.4f} ({macd_trend})"
                )
            else:
                print("   MACD: N/A")

            if indicators.get("K") and indicators.get("D"):
                kd_trend: Literal["å¤šé ­", "ç©ºé ­"] = (
                    "å¤šé ­" if indicators["K"] > indicators["D"] else "ç©ºé ­"
                )
                j_value: Optional[float] = indicators.get("J")
                if j_value is not None:
                    j_signal: Literal["å¼·å¤š", "å¼·ç©º", "æ­£å¸¸"] = (
                        "å¼·å¤š" if j_value > 100 else
                        "å¼·ç©º" if j_value < 0 else "æ­£å¸¸"
                    )
                    print(
                        f"   KDJ: K={indicators['K']:.2f}, "
                        f"D={indicators['D']:.2f}, "
                        f"J={j_value:.2f} ({kd_trend}, J:{j_signal})"
                    )
                else:
                    print(
                        f"   KDJ: K={indicators['K']:.2f}, "
                        f"D={indicators['D']:.2f}, "
                        f"J=N/A ({kd_trend})"
                    )

            if (indicators.get("BB_Upper") and
                indicators.get("BB_Middle") and
                    indicators.get("BB_Lower")):
                BB_Trend: Literal["ä¸Šå‡", "ä¸‹é™", "å¹³ç©©"] = (
                    "ä¸Šå‡" if indicators["BB_Upper"] > indicators["BB_Middle"]
                    else "ä¸‹é™"
                    if indicators["BB_Upper"] < indicators["BB_Middle"]
                    else "å¹³ç©©"
                )
                print(
                    f"   å¸ƒæ—é€šé“: ä¸Šè»Œ: {indicators['BB_Upper']:.2f}, "
                    f"ä¸­è»Œ: {indicators['BB_Middle']:.2f}, "
                    f"ä¸‹è»Œ: {indicators['BB_Lower']:.2f} | è¶¨å‹¢: {BB_Trend}"
                )
            else:
                print("   å¸ƒæ—é€šé“: N/A")

            if (indicators.get("MA5") and indicators.get("MA10") and
                    indicators.get("MA20") and indicators.get("MA60")):
                ma_trend: Literal["ä¸Šå‡", "ä¸‹é™", "å¹³ç©©"] = (
                    "ä¸Šå‡" if indicators["MA5"] > indicators["MA10"] else
                    "ä¸‹é™" if indicators["MA5"] < indicators["MA10"] else
                    "å¹³ç©©"
                )
                print(
                    f"   MA5: {indicators['MA5']:.2f} | "
                    f"MA10: {indicators['MA10']:.2f} | "
                    f"MA20: {indicators['MA20']:.2f} | "
                    f"MA60: {indicators['MA60']:.2f} | è¶¨å‹¢: {ma_trend}"
                )
            else:
                print("   ç§»å‹•å¹³å‡ç·š: N/A")

            # ä¿®å¾©ï¼šæª¢æŸ¥ time_range æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯
            time_range_info = data.get('time_range', 'N/A')
            print(
                f"   æ•¸æ“šç­†æ•¸: {data['total_records']} ({time_range_info}) | "
                f"é–“éš”: {data['interval']}")


def main() -> None:
    """ä¸»ç¨‹åº"""
    try:
        # å‰µå»ºåˆ†æå™¨
        analyzer: TechnicalAnalyzer = TechnicalAnalyzer()
        reporter: AnalysisReporter = AnalysisReporter()

        # æ¸¬è©¦è‚¡ç¥¨
        default_stocks: list[str] = ["2330", "AAPL", "NFLX"]

        # å¾å‘½ä»¤è¡Œåƒæ•¸ç²å–è‚¡ç¥¨ä»£è™Ÿ
        if len(sys.argv) > 1:
            target_stocks = sys.argv[1:]
            print(f"â„¹ï¸ ä½¿ç”¨å‘½ä»¤è¡Œå‚³å…¥çš„è‚¡ç¥¨ä»£è™Ÿ: {', '.join(target_stocks)}")
        else:
            target_stocks = default_stocks
            print(f"â„¹ï¸ æœªæä¾›å‘½ä»¤è¡Œåƒæ•¸ï¼Œä½¿ç”¨é è¨­è‚¡ç¥¨ä»£è™Ÿ: {', '.join(target_stocks)}")

        print("ğŸš€ é–‹å§‹æŠ€è¡“åˆ†æ")

        # åŸ·è¡Œåˆ†æ
        results: dict[str, Any] = analyzer.analyze_multiple_stocks(
            symbols=target_stocks,  # ä½¿ç”¨ target_stocks
            period=Period.MAX,
            interval=TimeInterval.DAY_1
        )

        # é¡¯ç¤ºçµæœ
        reporter.print_analysis_summary(results)

        # ä¿å­˜çµæœ
        saved_files: list[str] = analyzer.save_analysis_results(
            results, "json")

        print(f"\nğŸ’¾ å·²ä¿å­˜ {len(saved_files)} å€‹æª”æ¡ˆ:")
        for file in saved_files:
            print(f"   ğŸ“„ {file}")

    except Exception as e:
        logging.error(f"åŸ·è¡ŒéŒ¯èª¤: {e}")


if __name__ == "__main__":
    main()
